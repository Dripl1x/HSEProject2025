{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6990387c-ada0-405a-8319-f6fb2e474f46",
   "metadata": {
    "id": "6990387c-ada0-405a-8319-f6fb2e474f46"
   },
   "outputs": [],
   "source": [
    "# ! mkdir -p all_wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087cc2e-a700-4435-98fd-77c327e72e0e",
   "metadata": {
    "id": "b087cc2e-a700-4435-98fd-77c327e72e0e"
   },
   "outputs": [],
   "source": [
    "# ! find data/asr_calls_2_val -type f -name '*.wav' -exec cp {} all_wavs/ \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef063cdf-f198-4ee6-8415-558b4615a321",
   "metadata": {
    "id": "ef063cdf-f198-4ee6-8415-558b4615a321",
    "outputId": "2a0ee8b7-e65e-40ef-f11d-e97776a0ee04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.7/260.7 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=4.1.1 in /home/kuli/.local/lib/python3.10/site-packages (from librosa) (4.13.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/kuli/.local/lib/python3.10/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/kuli/.local/lib/python3.10/site-packages (from librosa) (1.5.0)\n",
      "Collecting soxr>=0.3.2\n",
      "  Downloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting soundfile>=0.12.1\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting msgpack>=1.0\n",
      "  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.0/378.0 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pooch>=1.1\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numba>=0.51.0\n",
      "  Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.3 in /home/kuli/.local/lib/python3.10/site-packages (from librosa) (2.2.5)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/kuli/.local/lib/python3.10/site-packages (from librosa) (1.6.1)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Collecting lazy_loader>=0.1\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/kuli/.local/lib/python3.10/site-packages (from librosa) (1.15.3)\n",
      "Requirement already satisfied: packaging in /home/kuli/.local/lib/python3.10/site-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0\n",
      "  Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /home/kuli/.local/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/kuli/.local/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/kuli/.local/lib/python3.10/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/kuli/.local/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/kuli/.local/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kuli/.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.5)\n",
      "Installing collected packages: soxr, msgpack, llvmlite, lazy_loader, audioread, soundfile, pooch, numba, librosa\n",
      "Successfully installed audioread-3.0.1 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.44.0 msgpack-1.1.0 numba-0.61.2 pooch-1.8.2 soundfile-0.13.1 soxr-0.5.0.post1\n"
     ]
    }
   ],
   "source": [
    "# ! python3 -m pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45wGmLQUsp5Y",
   "metadata": {
    "id": "45wGmLQUsp5Y"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A5SEYN9uhosM",
   "metadata": {
    "id": "A5SEYN9uhosM"
   },
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "haClpIfZht4g",
   "metadata": {
    "id": "haClpIfZht4g"
   },
   "outputs": [],
   "source": [
    "config = { #FIX\n",
    "    \"dataset\": {\n",
    "        \"train\": {\n",
    "            \"table\": \"./data/train.csv\",\n",
    "            \"data\": \"./data/asr_calls_spec/\"\n",
    "        },\n",
    "        \"val\": {\n",
    "            \"table\": \"./data/val.csv\",\n",
    "            \"data\": \"./data/asr_calls_spec/\"\n",
    "        }\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"batch_size\": 128,\n",
    "        \"grad_acum\": 1,\n",
    "        \"dtype\": \"float32\",\n",
    "        'shuffle': True,\n",
    "        'pin_memory': True,\n",
    "    },\n",
    "    \"val\": {\n",
    "        \"batch_size\": 1024,\n",
    "        \"grad_acum\": 1,\n",
    "        \"dtype\": \"float32\",\n",
    "        'shuffle': False,\n",
    "        'pin_memory': True,\n",
    "    },\n",
    "    \"vae\": {\n",
    "        \"freq\": 16000,\n",
    "        \"lenght\": 5,\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"latent_size\": 128,\n",
    "        \"freq_scale\": 4,\n",
    "        \"time_scale\": 4,\n",
    "    },\n",
    "    \"utils\": {\n",
    "        \"n_fft\": 800,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "iQ-5KIN8gPsm",
   "metadata": {
    "id": "iQ-5KIN8gPsm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(file_paths, test_size=0.2, seed=42):\n",
    "    return train_test_split(file_paths, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sAgY4MlFglSD",
   "metadata": {
    "id": "sAgY4MlFglSD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MelSpectrogramDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        wav_paths,              # список путей к .wav файлам\n",
    "        sr=22050,               # sample rate\n",
    "        duration=2.0,           # длительность аудио в секундах\n",
    "        n_mels=128,             # высота спектрограммы\n",
    "        hop_length=512,         # шаг окна\n",
    "        transform=None,         # дополнительные преобразования\n",
    "        to_log=True             # перевод в dB\n",
    "    ):\n",
    "        self.wav_paths = wav_paths\n",
    "        self.sr = sr\n",
    "        self.duration = duration\n",
    "        self.n_mels = n_mels\n",
    "        self.hop_length = hop_length\n",
    "        self.transform = transform\n",
    "        self.to_log = to_log\n",
    "        self.fixed_length = int(sr * duration)  # количество сэмплов\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wav_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.wav_paths[idx]\n",
    "\n",
    "        # Загружаем и обрезаем/дополняем\n",
    "        y, _ = librosa.load(path, sr=self.sr)\n",
    "        if len(y) < self.fixed_length:\n",
    "            y = np.pad(y, (0, self.fixed_length - len(y)), mode='constant')\n",
    "        else:\n",
    "            y = y[:self.fixed_length]\n",
    "\n",
    "        # Вычисляем мел-спектрограмму\n",
    "        mel = librosa.feature.melspectrogram(\n",
    "            y=y,\n",
    "            sr=self.sr,\n",
    "            n_mels=self.n_mels,\n",
    "            hop_length=self.hop_length\n",
    "        )\n",
    "\n",
    "        # В логарифмический масштаб\n",
    "        if self.to_log:\n",
    "            mel = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "        # Нормализация (опционально)\n",
    "        mel = (mel - mel.min()) / (mel.max() - mel.min() + 1e-6)\n",
    "\n",
    "        # В тензор (1, H, W)\n",
    "        mel_tensor = torch.tensor(mel, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        if self.transform:\n",
    "            mel_tensor = self.transform(mel_tensor)\n",
    "\n",
    "        return mel_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "V4AD3Vqoguc8",
   "metadata": {
    "id": "V4AD3Vqoguc8"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_dataloaders(train_files, val_files, batch_size=32):\n",
    "    train_dataset = MelSpectrogramDataset(train_files)\n",
    "    val_dataset = MelSpectrogramDataset(val_files)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "Jq6sYn1Hh3sF",
   "metadata": {
    "id": "Jq6sYn1Hh3sF"
   },
   "outputs": [],
   "source": [
    "class VAE_Audio(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Энкодер\n",
    "        self.encoder_input = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, 1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(1, 8, 3, 1, 1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(8, 16, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.encoder_main = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, 1, (1, 0)),  # Коррекция паддинга для нечётных размеров\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(32, 32, 3, 2, (1, 0)),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(32, 32, 3, 2, (1, 0)),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(32, 16, 3, 2, (1, 0))\n",
    "        )\n",
    "\n",
    "        self.encoder_squeeze = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, 2, (1, 0)),\n",
    "            nn.Conv2d(32, 64, 3, 2, (1, 0))\n",
    "        )\n",
    "\n",
    "        self.encoder_mu = nn.Conv2d(64, 64, 1)\n",
    "        self.encoder_logvar = nn.Conv2d(64, 64, 1)\n",
    "\n",
    "        # Декодер\n",
    "        self.decoder_unsqueeze = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 3, 2, (1, 0), output_padding=(1, 0)),\n",
    "            nn.ConvTranspose2d(32, 16, 3, 2, (1, 0), output_padding=(1, 0)),\n",
    "            nn.ConvTranspose2d(16, 32, 3, 2, (1, 0), output_padding=(1, 0)),\n",
    "            nn.ConvTranspose2d(32, 32, 3, 2, (1, 0), output_padding=(1, 0)),\n",
    "            nn.ConvTranspose2d(32, 16, 3, 2, (1, 0), output_padding=(1, 0))\n",
    "        )\n",
    "\n",
    "        self.decoder_output = nn.Sequential(\n",
    "            nn.Conv2d(16, 8, 3, padding=(1, 0)),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(8, 1, 1),\n",
    "            nn.AdaptiveAvgPool2d((128, 87)),  # Форсируем нужный размер\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder_input(x)\n",
    "        x = self.encoder_main(x)\n",
    "        x = self.encoder_squeeze(x)\n",
    "        return self.encoder_mu(x), self.encoder_logvar(x)\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.decoder_unsqueeze(z)\n",
    "        return self.decoder_output(z)\n",
    "\n",
    "    # Остальные методы остаются без изменений\n",
    "    def sample(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def KLD_loss(self, mu, logvar, q=0.02):\n",
    "        kld = -0.5 * (1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        kld = torch.clamp(kld, min=q)\n",
    "        return kld.mean()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.sample(x)\n",
    "        return self.decode(z), z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6GU6h9NRiJ5O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6GU6h9NRiJ5O",
    "outputId": "3b4102c9-8021-43a6-b181-4c41572479fc"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "class AvegereMeter:\n",
    "    def __init__(self,):\n",
    "        self.arr = []\n",
    "    def __call__(self, item, n=1):\n",
    "        if n<=1:\n",
    "            self.arr.extend([item])\n",
    "        else:\n",
    "            self.arr.extend([item]*n)\n",
    "    def __str__(self,) -> str:\n",
    "        return str(np.mean(np.array(self.arr)))\n",
    "    def zero(self,):\n",
    "        self.arr=[]\n",
    "\n",
    "class VAE_Trainer:\n",
    "    def __init__(self, model, train_dataloader, val_dataloader,):\n",
    "        self.model = model\n",
    "        self.tdl = train_dataloader\n",
    "        self.vdl = val_dataloader\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        self.rec_loss = nn.MSELoss()\n",
    "        self.loss_meter = AvegereMeter()\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "    def train_loop(self, k=0.01):\n",
    "        self.model.train()\n",
    "        self.loss_meter.zero()\n",
    "        for batch in tqdm(self.tdl):\n",
    "            with torch.autocast('cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                z, mu, logvar = self.model.sample(batch)\n",
    "                output = self.model.decode(z)\n",
    "                loss = self.rec_loss(output, batch)+k*self.model.KLD_loss(mu, logvar)\n",
    "            loss.backward()\n",
    "            self.loss_meter(loss.item(), batch.shape[0])\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "        self.scheduler.step()\n",
    "        print(\"Loss = \"+self.loss_meter.__str__())\n",
    "\n",
    "    def save_image(self, audio, output, iter = 0):\n",
    "        idx = torch.randint(0, audio.shape[0], (1,)).item()\n",
    "        input_tensor = audio[idx].cpu().detach().clamp(0, 1).to(torch.float32)\n",
    "        output_tensor = output[idx].cpu().detach().clamp(0, 1).to(torch.float32)\n",
    "\n",
    "        transform = transforms.ToPILImage('RGB')\n",
    "        input_image = transform(torch.cat([input_tensor]*3, dim=0))\n",
    "        output_image = transform(torch.cat([output_tensor]*3, dim=0))\n",
    "\n",
    "        input_image.save(f'./data/asr_calls_spec/train/input_{iter}.png')\n",
    "        output_image.save(f'./data/asr_calls_spec/train/output_{iter}.png')\n",
    "\n",
    "    def val_loop(self):\n",
    "        self.model.eval()\n",
    "        self.loss_meter.zero()\n",
    "        flag = 1\n",
    "        for batch in tqdm(self.vdl):\n",
    "            with torch.autocast('cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                z, mu, logvar = self.model.sample(batch)\n",
    "                output = self.model.decode(z)\n",
    "                loss = self.rec_loss(output, batch)\n",
    "                if (flag):\n",
    "                    self.save_image(batch, output, i)\n",
    "                flag = 0\n",
    "                self.loss_meter(loss.item(), batch.shape[0])\n",
    "        print(\"Val loss = \"+self.loss_meter.__str__())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fR7ps-TSuS0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fR7ps-TSuS0a",
    "outputId": "6a5d9589-2dca-4ee8-cc03-92b2a6721a0d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/10 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/83 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|█                                                                                   | 1/83 [00:23<31:35, 23.12s/it]\u001b[A\n",
      "  2%|██                                                                                  | 2/83 [00:45<30:50, 22.85s/it]\u001b[A\n",
      "  4%|███                                                                                 | 3/83 [01:07<29:51, 22.39s/it]\u001b[A\n",
      "  5%|████                                                                                | 4/83 [01:30<29:35, 22.48s/it]\u001b[A\n",
      "  6%|█████                                                                               | 5/83 [01:52<29:02, 22.34s/it]\u001b[A\n",
      "  7%|██████                                                                              | 6/83 [02:12<27:55, 21.76s/it]\u001b[A\n",
      "  8%|███████                                                                             | 7/83 [02:33<27:00, 21.33s/it]\u001b[A\n",
      " 10%|████████                                                                            | 8/83 [02:54<26:33, 21.24s/it]\u001b[A\n",
      " 11%|█████████                                                                           | 9/83 [03:17<26:46, 21.71s/it]\u001b[A\n",
      " 12%|██████████                                                                         | 10/83 [03:37<25:51, 21.25s/it]\u001b[A\n",
      " 13%|███████████                                                                        | 11/83 [03:59<25:48, 21.51s/it]\u001b[A\n",
      " 14%|████████████                                                                       | 12/83 [04:23<26:24, 22.32s/it]\u001b[A\n",
      " 16%|█████████████                                                                      | 13/83 [04:46<26:22, 22.60s/it]\u001b[A\n",
      " 17%|█████████████▉                                                                     | 14/83 [05:08<25:34, 22.23s/it]\u001b[A\n",
      " 18%|███████████████                                                                    | 15/83 [05:28<24:37, 21.73s/it]\u001b[A\n",
      " 19%|████████████████                                                                   | 16/83 [05:52<24:46, 22.18s/it]\u001b[A\n",
      " 20%|█████████████████                                                                  | 17/83 [06:12<23:42, 21.55s/it]\u001b[A\n",
      " 22%|██████████████████                                                                 | 18/83 [06:33<23:13, 21.44s/it]\u001b[A\n",
      " 23%|███████████████████                                                                | 19/83 [06:56<23:25, 21.97s/it]\u001b[A\n",
      " 24%|████████████████████                                                               | 20/83 [07:18<23:03, 21.96s/it]\u001b[A\n",
      " 25%|█████████████████████                                                              | 21/83 [07:41<22:58, 22.23s/it]\u001b[A\n",
      " 27%|██████████████████████                                                             | 22/83 [08:02<22:21, 21.99s/it]\u001b[A\n",
      " 28%|███████████████████████                                                            | 23/83 [08:22<21:13, 21.23s/it]\u001b[A\n",
      " 29%|████████████████████████                                                           | 24/83 [08:43<20:53, 21.25s/it]\u001b[A\n",
      " 30%|█████████████████████████                                                          | 25/83 [09:05<20:52, 21.59s/it]\u001b[A\n",
      " 31%|██████████████████████████                                                         | 26/83 [09:27<20:28, 21.56s/it]\u001b[A\n",
      " 33%|███████████████████████████                                                        | 27/83 [09:48<19:54, 21.32s/it]\u001b[A\n",
      " 34%|███████████████████████████▉                                                       | 28/83 [10:07<18:57, 20.68s/it]\u001b[A\n",
      " 35%|█████████████████████████████                                                      | 29/83 [10:28<18:43, 20.81s/it]\u001b[A\n",
      " 36%|██████████████████████████████                                                     | 30/83 [10:50<18:49, 21.30s/it]\u001b[A\n",
      " 37%|███████████████████████████████                                                    | 31/83 [11:10<18:01, 20.79s/it]\u001b[A\n",
      " 39%|████████████████████████████████                                                   | 32/83 [11:30<17:33, 20.66s/it]\u001b[A\n",
      " 40%|█████████████████████████████████                                                  | 33/83 [11:52<17:26, 20.92s/it]\u001b[A\n",
      " 41%|██████████████████████████████████                                                 | 34/83 [12:11<16:38, 20.38s/it]\u001b[A\n",
      " 42%|███████████████████████████████████                                                | 35/83 [12:31<16:11, 20.25s/it]\u001b[A\n",
      " 43%|████████████████████████████████████                                               | 36/83 [12:53<16:21, 20.89s/it]\u001b[A\n",
      " 45%|█████████████████████████████████████                                              | 37/83 [13:14<15:57, 20.81s/it]\u001b[A\n",
      " 46%|██████████████████████████████████████                                             | 38/83 [13:35<15:33, 20.75s/it]\u001b[A\n",
      " 47%|███████████████████████████████████████                                            | 39/83 [13:54<14:58, 20.42s/it]\u001b[A\n",
      " 48%|████████████████████████████████████████                                           | 40/83 [14:15<14:43, 20.55s/it]\u001b[A\n",
      " 49%|█████████████████████████████████████████                                          | 41/83 [14:34<14:03, 20.08s/it]\u001b[A\n",
      " 51%|██████████████████████████████████████████                                         | 42/83 [14:56<14:03, 20.57s/it]\u001b[A\n",
      " 52%|███████████████████████████████████████████                                        | 43/83 [15:16<13:40, 20.51s/it]\u001b[A\n",
      " 53%|████████████████████████████████████████████                                       | 44/83 [15:35<12:57, 19.93s/it]\u001b[A\n",
      " 54%|█████████████████████████████████████████████                                      | 45/83 [15:56<12:56, 20.42s/it]\u001b[A\n",
      " 55%|██████████████████████████████████████████████                                     | 46/83 [16:16<12:29, 20.25s/it]\u001b[A\n",
      " 57%|███████████████████████████████████████████████                                    | 47/83 [16:36<12:03, 20.10s/it]\u001b[A\n",
      " 58%|████████████████████████████████████████████████                                   | 48/83 [16:58<12:01, 20.63s/it]\u001b[A\n",
      " 59%|█████████████████████████████████████████████████                                  | 49/83 [17:17<11:26, 20.19s/it]\u001b[A\n",
      " 60%|██████████████████████████████████████████████████                                 | 50/83 [17:36<10:58, 19.95s/it]\u001b[A\n",
      " 61%|███████████████████████████████████████████████████                                | 51/83 [17:59<11:00, 20.63s/it]\u001b[A\n",
      " 63%|████████████████████████████████████████████████████                               | 52/83 [18:18<10:31, 20.37s/it]\u001b[A\n",
      " 64%|████████████████████████████████████████████████████▉                              | 53/83 [18:37<09:58, 19.96s/it]\u001b[A\n",
      " 65%|██████████████████████████████████████████████████████                             | 54/83 [18:58<09:47, 20.27s/it]\u001b[A\n",
      " 66%|███████████████████████████████████████████████████████                            | 55/83 [19:18<09:24, 20.17s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████▉                           | 56/83 [19:38<08:59, 19.98s/it]\u001b[A\n",
      " 69%|█████████████████████████████████████████████████████████                          | 57/83 [20:00<08:58, 20.73s/it]\u001b[A\n",
      " 70%|██████████████████████████████████████████████████████████                         | 58/83 [20:21<08:38, 20.74s/it]\u001b[A\n",
      " 71%|███████████████████████████████████████████████████████████                        | 59/83 [20:41<08:08, 20.36s/it]\u001b[A\n",
      " 72%|████████████████████████████████████████████████████████████                       | 60/83 [21:01<07:49, 20.41s/it]\u001b[A\n",
      " 73%|█████████████████████████████████████████████████████████████                      | 61/83 [21:22<07:32, 20.58s/it]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████                     | 62/83 [21:41<07:05, 20.25s/it]\u001b[A\n",
      " 76%|███████████████████████████████████████████████████████████████                    | 63/83 [22:02<06:48, 20.44s/it]\u001b[A\n",
      " 77%|████████████████████████████████████████████████████████████████                   | 64/83 [22:22<06:24, 20.24s/it]\u001b[A\n",
      " 78%|█████████████████████████████████████████████████████████████████                  | 65/83 [22:41<05:56, 19.79s/it]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████████                 | 66/83 [23:02<05:44, 20.26s/it]\u001b[A\n",
      " 81%|███████████████████████████████████████████████████████████████████                | 67/83 [23:21<05:17, 19.87s/it]\u001b[A\n",
      " 82%|████████████████████████████████████████████████████████████████████               | 68/83 [23:41<04:57, 19.83s/it]\u001b[A\n",
      " 83%|█████████████████████████████████████████████████████████████████████              | 69/83 [24:02<04:44, 20.29s/it]\u001b[A\n",
      " 84%|██████████████████████████████████████████████████████████████████████             | 70/83 [24:22<04:22, 20.16s/it]\u001b[A\n",
      " 86%|███████████████████████████████████████████████████████████████████████            | 71/83 [24:42<04:00, 20.08s/it]\u001b[A\n",
      " 87%|████████████████████████████████████████████████████████████████████████           | 72/83 [25:03<03:44, 20.41s/it]\u001b[A\n",
      " 88%|█████████████████████████████████████████████████████████████████████████          | 73/83 [25:25<03:26, 20.68s/it]\u001b[A\n",
      " 89%|██████████████████████████████████████████████████████████████████████████         | 74/83 [25:44<03:03, 20.44s/it]\u001b[A\n",
      " 90%|███████████████████████████████████████████████████████████████████████████        | 75/83 [26:04<02:41, 20.22s/it]\u001b[A\n",
      " 92%|████████████████████████████████████████████████████████████████████████████       | 76/83 [26:26<02:25, 20.81s/it]\u001b[A\n",
      " 93%|█████████████████████████████████████████████████████████████████████████████      | 77/83 [26:46<02:02, 20.48s/it]\u001b[A\n",
      " 94%|██████████████████████████████████████████████████████████████████████████████     | 78/83 [27:06<01:41, 20.24s/it]\u001b[A\n",
      " 95%|███████████████████████████████████████████████████████████████████████████████    | 79/83 [27:28<01:23, 20.92s/it]\u001b[A\n",
      " 96%|████████████████████████████████████████████████████████████████████████████████   | 80/83 [27:47<01:01, 20.38s/it]\u001b[A\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████████  | 81/83 [28:07<00:40, 20.15s/it]\u001b[A\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████████ | 82/83 [28:29<00:20, 20.64s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 83/83 [28:37<00:00, 20.69s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.03672541230334624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|████                                                                                | 1/21 [00:09<03:08,  9.42s/it]\u001b[A\n",
      " 10%|████████                                                                            | 2/21 [00:19<03:04,  9.72s/it]\u001b[A\n",
      " 14%|████████████                                                                        | 3/21 [00:28<02:52,  9.59s/it]\u001b[A\n",
      " 19%|████████████████                                                                    | 4/21 [00:36<02:29,  8.77s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "vae = VAE_Audio()\n",
    "\n",
    "file_paths = list(Path('data/asr_calls_wavs').rglob(\"*.wav\"))\n",
    "train_files, val_files = split_dataset(file_paths)\n",
    "\n",
    "train_dataloader, val_dataloader = get_dataloaders(train_files, val_files, batch_size=config['train']['batch_size'])\n",
    "\n",
    "\n",
    "\n",
    "trainer = VAE_Trainer(vae, train_dataloader, val_dataloader)\n",
    "\n",
    "\n",
    "i = 0\n",
    "for epoch in tqdm(range(10)):\n",
    "    i += 1\n",
    "    trainer.train_loop(0.01)\n",
    "    trainer.val_loop()\n",
    "torch.save(vae.state_dict(), \"vae_spec.pt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
